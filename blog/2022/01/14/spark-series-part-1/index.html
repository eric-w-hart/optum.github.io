<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Optum Open Source RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Optum Open Source Atom Feed"><title data-react-helmet="true">Migrating ETL to Spark - Motivation and Quick Start | Optum Open Source</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://optum.github.io/blog/2022/01/14/spark-series-part-1"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Migrating ETL to Spark - Motivation and Quick Start | Optum Open Source"><meta data-react-helmet="true" name="description" content="Note: this is the first article in a multi-part series. Future installments will cover topics like performance optimization, validation, and refactoring."><meta data-react-helmet="true" property="og:description" content="Note: this is the first article in a multi-part series. Future installments will cover topics like performance optimization, validation, and refactoring."><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-01-14T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://www.linkedin.com/in/wrschneider"><meta data-react-helmet="true" property="article:tag" content="Spark,ETL,Engineering"><link data-react-helmet="true" rel="icon" href="/img/open_source.svg"><link data-react-helmet="true" rel="canonical" href="https://optum.github.io/blog/2022/01/14/spark-series-part-1"><link data-react-helmet="true" rel="alternate" href="https://optum.github.io/blog/2022/01/14/spark-series-part-1" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://optum.github.io/blog/2022/01/14/spark-series-part-1" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.50574292.css">
<link rel="preload" href="/assets/js/runtime~main.8dcb1336.js" as="script">
<link rel="preload" href="/assets/js/main.2b64b905.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/Optum(R)_4C.png" alt="Optum Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/Optum(R)_4C.png" alt="Optum Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Optum Open Source</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Open Source Program Office</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/philosophy">Philosophy</a></li><li><a class="dropdown__link" href="/docs/guilds">Guilds</a></li><li><a class="dropdown__link" href="/docs/givingprogram">Giving Program</a></li><li><a class="dropdown__link" href="/docs/memberships">Memberships</a></li><li><a class="dropdown__link" href="/communities">Our Projects</a></li><li><a class="dropdown__link" href="/contributors">Our Engineers</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a aria-current="page" class="navbar__link" href="/blog">Blog</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/blog/tags/culture">Culture</a></li><li><a class="dropdown__link" href="/blog/tags/engineering">Engineering</a></li><li><a class="dropdown__link" href="/blog/tags/ml-ai">ML/AI</a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.youtube.com/watch?v=9sdASFlw0As" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Why Contribute to Open Source?<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/Optum" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2022/02/08/spark-part2-refactoring">Migrating ETL to Spark - Refactoring</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2022/01/25/data-streaming-at-scale-with-benthos">Data Streaming At Scale With Benthos</a></li><li class="sidebarItem_CF0Q"><a aria-current="page" class="sidebarItemLink_miNk sidebarItemLinkActive_RRTD" href="/blog/2022/01/14/spark-series-part-1">Migrating ETL to Spark - Motivation and Quick Start</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2021/11/15/package-model-analytic-reuse">Packaging models and analytics for reuse -  API vs. Inner Source.</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2021/10/21/s3-to-azure-copy">Copying data between AWS and Azure</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">Migrating ETL to Spark - Motivation and Quick Start</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-01-14T00:00:00.000Z" itemprop="datePublished">January 14, 2022</time> Â· <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/wrschneider" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_o0gy" src="https://avatars.githubusercontent.com/u/3975157?v=4" alt="Bill Schneider"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/wrschneider" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Bill Schneider</span></a></div><small class="avatar__subtitle" itemprop="description">Sr. Principal Engineer</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p><em>Note: this is the first article in a multi-part series. Future installments will cover topics like performance optimization, validation, and refactoring.</em></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="advantages-of-spark">Advantages of Spark<a class="hash-link" href="#advantages-of-spark" title="Direct link to heading">â€‹</a></h3><p>At Optum, we are migrating some of our ETL processes to <a href="https://spark.apache.org" target="_blank" rel="noopener noreferrer">Apache Spark</a>, an open-source framework for distributed computing. Many of these processes were previously running on relational databases, based on SQL queries and stored procedures. The data transformations can range from simple cleansing, to table joins and aggregations, to complex business logic. The results are then stored in a data warehouse for use in analytics applications.</p><p>While DBs have their advatanges, there&#x27;s a limit to how big of a dataset you can process in a given timeframe. That&#x27;s because databases are generally meant to scale vertically -- when you have a bigger dataset, you get a bigger server. At some point, though, you can&#x27;t make your server any bigger. Spark, like other big-data platforms, is meant to scale horizontally -- when you get a bigger dataset, you add <em>more</em> servers.</p><p>Horizontal scaling is especially useful when you run Spark in the public cloud, given the options for on-demand and serverless compute. Cloud gives the flexibility to scale up resources to meet demand rather than queueing jobs until there is capacity on a fixed server or Spark cluster. Then you pay for your compute resources by the CPU-hour, rather than having to size your cluster for the peak.</p><p>Spark lets you build your data transformations with SQL syntax or SQL-like constructs, so there is a natural transition from a SQL-based ETL process to Spark. Rather than processing joins and aggregations on a single server, though, Spark datasets are distributed. Each node in a cluster works on a partition of the data in parallel. Intermediate results from one <code>JOIN</code> or <code>GROUP BY</code> are then redistributed, or <em>shuffled</em>, to different nodes for the next operation.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="getting-started-with-spark-sql">Getting started with Spark SQL<a class="hash-link" href="#getting-started-with-spark-sql" title="Direct link to heading">â€‹</a></h3><p><em>For this and future sections, I assume you have some familiarity with Spark and how to author and run Spark jobs. There are plenty of tutorials out there, including some good resources in the <a href="https://spark.apache.org/docs/latest/sql-getting-started.html" target="_blank" rel="noopener noreferrer">Spark documentation</a></em></p><p>Spark offers SQL syntax, but Spark is not a database! Spark datasets are in-memory, and are explicitly read or written from storage. The separation of storage and compute helps with horizontal scale as both can be scaled independently. Typically if our job is running in the cloud, data will be stored in object/blob storage.</p><p>A typical ETL process might have something like this:</p><div class="codeBlockContainer_I0IT language-sql theme-code-block"><div class="codeBlockContent_wNvx sql"><pre tabindex="0" class="prism-code language-sql codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">TABLE</span><span class="token plain"> patient_visits</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">patient_id </span><span class="token keyword" style="font-style:italic">bigint</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> patient_name </span><span class="token keyword" style="font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token number" style="color:rgb(247, 140, 108)">100</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> visit_count </span><span class="token keyword" style="font-style:italic">int</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">INTO</span><span class="token plain"> patient_visits</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">SELECT</span><span class="token plain"> patient_id</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> patient_name</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">count</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token number" style="color:rgb(247, 140, 108)">1</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> visit_count</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">FROM</span><span class="token plain">  patient</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">JOIN</span><span class="token plain">  visit </span><span class="token keyword" style="font-style:italic">ON</span><span class="token plain"> patient</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">patient_id </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> visit</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">patient_id</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">GROUP</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">BY</span><span class="token plain"> patient_id</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> patient_name</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>In Spark, there is no <code>INSERT</code> statement, only <code>SELECT</code>. When you run the SQL <code>SELECT</code> query in Spark SQL, you would get back a DataFrame, which is a tabular abstraction on top of a Spark Resilient Distributed Dataset (RDD). You would then write the DataFrame explicitly to storage:</p><div class="codeBlockContainer_I0IT language-scala theme-code-block"><div class="codeBlockContent_wNvx scala"><pre tabindex="0" class="prism-code language-scala codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token plain">val df = spark.sql(&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  SELECT patient_id, patient_name, count(1) visit_count</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  FROM  patient</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  JOIN  visit ON patient.patient_id = visit.patient_id</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  GROUP BY patient_id, patient_name</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">val targetLocation = // s3 or Azure blob store path</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">df.write.parquet(targetLocation)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The output format is typically <a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html" target="_blank" rel="noopener noreferrer">Parquet</a>, which uses compressed and column-oriented storage. That means if you run a query that only reads two columns, you only retrieve the data for those two columns from storage. Most database tables use row-oriented storage by default which means you read all the columns from storage unless you can use a covering index. The Parquet format also contains schema information, like a database table. So unlike text formats, there is a distinction between <code>3</code> (integer), <code>3.000....</code> (floating point) and <code>3.00</code> (fixed-point, two decimal places).</p><p>Many of your SQL SELECT statements, from SQL Server/Oracle/etc. can often be copy-paste (minus the <code>INSERT</code>) and run with minimal modification to address vendor-specific differences for things like string concatenation (SQL Server uses <code>+</code>), SQL <code>isnull</code> vs. Oracle <code>nvl</code> vs. <code>coalesce</code>, date functions etc.</p><p>But there are a few points of caution to look out for:</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="updates-and-deletes">UPDATEs and DELETEs<a class="hash-link" href="#updates-and-deletes" title="Direct link to heading">â€‹</a></h3><p>Sometimes SQL-based ETL procesess use <code>UPDATE</code> or <code>DELETE</code> statements. Or you may have a series of <code>INSERT</code> statements a table with <code>WHERE NOT EXISTS</code> to prevent duplicates.</p><p>These cannot be copied as-is to Spark. Rather, you need to do some refactoring to work with <code>SELECT</code> (read) operations only. For example:</p><ul><li>Multiple <code>INSERT</code> statements become multiple <code>SELECT</code> statements combined with <code>UNION</code></li><li>An <code>UPDATE</code> becomes an outer join and combined in the original <code>SELECT</code></li><li>A <code>DELETE</code> becomes a filter against the original <code>SELECT</code></li><li>You might need to write the original <code>SELECT</code> results to a temporary location.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="correlated-subqueries">Correlated subqueries<a class="hash-link" href="#correlated-subqueries" title="Direct link to heading">â€‹</a></h3><p>Some kinds of subqueries need to be re-written. For example, Spark does not support <code>EXISTS</code>/<code>NOT EXISTS</code> subqueries. These must be rewritten as <a href="https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html" target="_blank" rel="noopener noreferrer">semi-joins or anti-joins</a>. For example:</p><div class="codeBlockContainer_I0IT language-sql theme-code-block"><div class="codeBlockContent_wNvx sql"><pre tabindex="0" class="prism-code language-sql codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">select</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">*</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> table_a a </span><span class="token keyword" style="font-style:italic">where</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">not</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">exists</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token keyword" style="font-style:italic">select</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">1</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> table_b b </span><span class="token keyword" style="font-style:italic">where</span><span class="token plain"> b</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">a_id</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">a_id</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>becomes</p><div class="codeBlockContainer_I0IT language-sql theme-code-block"><div class="codeBlockContent_wNvx sql"><pre tabindex="0" class="prism-code language-sql codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">select</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">*</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> table_a a ANTI </span><span class="token keyword" style="font-style:italic">JOIN</span><span class="token plain"> table_b </span><span class="token keyword" style="font-style:italic">on</span><span class="token plain"> a</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">a_id </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> b</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">a_id</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="implicit-type-conversions">Implicit type conversions<a class="hash-link" href="#implicit-type-conversions" title="Direct link to heading">â€‹</a></h3><p>In SQL-based ETL processes, an <code>INSERT</code> statement may do an implicit type conversion to the target column. In Spark you will have to do that conversion explicitly.</p><p>At the same time, Spark may do some implicit type conversion of its own on arithmetic and aggregate functions. For example, a <code>SUM</code> in Spark will promote the underlying numeric type: an <code>int</code> will become a <code>bigint</code>, a <code>decimal(p, s)</code> will become <code>decimal(p + 10, s)</code> (expand by ten digits). So if you intend to preserve the datatypes that correspond to your original database schema, you will have to cast explicitly.</p><p>For example:</p><div class="codeBlockContainer_I0IT language-scala theme-code-block"><div class="codeBlockContent_wNvx scala"><pre tabindex="0" class="prism-code language-scala codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token plain">val df = spark.sql(&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  SELECT patient_id, patient_name, cast(count(1) as integer) visit_count</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  FROM  patient</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  JOIN  visit ON patient.patient_id = visit.patient_id</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  GROUP BY patient_id, patient_name</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="decimal-truncation-on-division">Decimal truncation on division<a class="hash-link" href="#decimal-truncation-on-division" title="Direct link to heading">â€‹</a></h3><p>On some databases (SQL Server for example), division operations on decimal types may truncate to a <a href="https://docs.microsoft.com/en-us/sql/t-sql/data-types/precision-scale-and-length-transact-sql?view=sql-server-ver15" target="_blank" rel="noopener noreferrer">specified number of decimal places</a>. Spark follows <a href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/DecimalPrecision.scala" target="_blank" rel="noopener noreferrer">similar rules to SQL Server</a> but rounds rather than truncates.</p><p>If your goal is to reproduce exact results in Spark (useful to simplify validation in a technology migration), you may need to define a <a href="https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html" target="_blank" rel="noopener noreferrer">user-defined function</a>:</p><div class="codeBlockContainer_I0IT language-scala theme-code-block"><div class="codeBlockContent_wNvx scala"><pre tabindex="0" class="prism-code language-scala codeBlock_jd64 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#bfc7d5"><span class="token plain">val divide = udf((x: BigDecimal, y: BigDecimal, scale: Int) =&gt; x.divide(y, scale, RoundingMode.FLOOR))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spark.udf.register(&quot;divide&quot;, divide)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spark.sql(&quot;select divide(foo, bar, 6) as ratio from table&quot;)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="coming-up">Coming up<a class="hash-link" href="#coming-up" title="Direct link to heading">â€‹</a></h3><p>The next article will discuss going beyond copy-paste SQL, to refactoring and using the Spark DataFrame API directly.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/spark">Spark</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/etl">ETL</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/engineering">Engineering</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2022/01/25/data-streaming-at-scale-with-benthos"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Data Streaming At Scale With Benthos</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2021/11/15/package-model-analytic-reuse"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Packaging models and analytics for reuse -  API vs. Inner Source.</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#advantages-of-spark" class="table-of-contents__link toc-highlight">Advantages of Spark</a></li><li><a href="#getting-started-with-spark-sql" class="table-of-contents__link toc-highlight">Getting started with Spark SQL</a></li><li><a href="#updates-and-deletes" class="table-of-contents__link toc-highlight">UPDATEs and DELETEs</a></li><li><a href="#correlated-subqueries" class="table-of-contents__link toc-highlight">Correlated subqueries</a></li><li><a href="#implicit-type-conversions" class="table-of-contents__link toc-highlight">Implicit type conversions</a></li><li><a href="#decimal-truncation-on-division" class="table-of-contents__link toc-highlight">Decimal truncation on division</a></li><li><a href="#coming-up" class="table-of-contents__link toc-highlight">Coming up</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/communities">Our Projects</a></li><li class="footer__item"><a class="footer__link-item" href="/contributors">Our Engineers</a></li></ul></div><div class="col footer__col"><div class="footer__title">Administration</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/optumcoc">Contributor Code of Conduct</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/optumicla">Individual Contributor License Agreement</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/optumlic">Project Licensing</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/attribution">Code Attribution</a></li></ul></div><div class="col footer__col"><div class="footer__title">Work With Us</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/Optum" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="mailto:opensource@optum.com" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>opensource@optum.com<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://careers.unitedhealthgroup.com/search-jobs?kw=&amp;sp=&amp;re=US&amp;jf=20" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Career Opportunities<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items"><li class="footer__item"><a href="https://www.optum.com/terms-of-use.html" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Terms of use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://www.optum.com/privacy-policy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Optum, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.8dcb1336.js"></script>
<script src="/assets/js/main.2b64b905.js"></script>
</body>
</html>